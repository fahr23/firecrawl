# KAP Scraping Roadmap & Strategy

## Understanding KAP Architecture

**KAP (`kap.org.tr`) is a Single Page Application (SPA)** that loads data dynamically via an internal API. 

### Why Standard HTML Crawling Fails

- The HTML interface doesn't contain actual report links
- Links are generated by JavaScript from JSON API responses
- PDFs are served as binary files, not web pages
- To crawl HTML, you'd need to:
  - Render JavaScript
  - Scroll infinitely through search results
  - Click thousands of elements
  - Wait for dynamic content loading

### The Efficient Approach: Direct API Access

**Bypass the HTML interface entirely** and talk directly to the API endpoint, just like the browser does.

---

## Strategic Roadmap

### Phase 1: API Discovery âœ…

**Target Endpoint:** `https://www.kap.org.tr/tr/api/memberDisclosureQuery`

- This is the endpoint KAP uses to populate its search results
- Returns structured JSON data with all disclosure metadata
- Much faster than HTML parsing (500+ records in seconds)

### Phase 2: Data Retrieval âœ…

**Method:** `POST` request with JSON payload

**Payload Structure:**
```json
{
  "fromDate": "2026-01-18",      // YYYY-MM-DD format
  "toDate": "2026-01-25",
  "memberType": "IGS",           // BIST companies
  "disclosureClass": "",          // Optional: "FR" for Financial Reports
  "subjectList": [],              // Optional: filter by specific subjects
  // ... other filters
}
```

**Response:** Array of disclosure objects containing:
- `disclosureIndex` - **Key ID for PDF download**
- `kapTitle` - Report title
- `publishDate` - Publication date
- `stockCodes` - Company codes (comma-separated)
- `subject` - Report subject
- `summary` - Report summary
- `disclosureType` - Type of disclosure
- `attachmentCount` - Number of attachments
- And more...

### Phase 3: PDF Retrieval âœ…

**URL Pattern:** `https://www.kap.org.tr/tr/BildirimPdf/{disclosureIndex}`

- Construct download URL using `disclosureIndex` from API response
- Download PDFs as binary files
- Store locally or process immediately

### Phase 4: Data Processing (Optional)

After downloading PDFs:
1. Extract text using PDF parsers (`pypdf`, `PyMuPDF`, `LlamaParse`)
2. Analyze content with LLM for sentiment analysis
3. Store extracted text and analysis in database

---

## Implementation Details

### Current Implementation

The scraper (`scrapers/kap_scraper.py`) implements Phases 1-3:

1. **API Request:**
   ```python
   api_url = f"{BASE_URL}/tr/api/memberDisclosureQuery"
   payload = {
       "fromDate": start_date.strftime("%Y-%m-%d"),
       "toDate": end_date.strftime("%Y-%m-%d"),
       "memberType": "IGS",
       # ... other filters
   }
   response = requests.post(api_url, json=payload, headers=headers)
   data = response.json()  # Array of disclosures
   ```

2. **Data Extraction:**
   ```python
   for item in data:
       disclosure_index = item.get("disclosureIndex")
       stock_codes = item.get("stockCodes", "").split(",")
       # ... extract other fields
   ```

3. **PDF URL Construction:**
   ```python
   pdf_url = f"{BASE_URL}/tr/BildirimPdf/{disclosure_index}"
   ```

4. **Database Storage:**
   - Metadata stored in `kap_reports` table
   - PDF URL stored in `data.url` field
   - All API response data preserved in `data` JSON field

### Date Format

**Confirmed Working Format:** `YYYY-MM-DD` (e.g., `2026-01-25`)
- Used in working `getKAPReports.py`
- Verified to work with KAP API

**Alternative Format:** `DD.MM.YYYY` (e.g., `25.01.2026`)
- May also work, but not verified
- Current implementation uses `YYYY-MM-DD`

---

## Why Not Use Firecrawl for This?

Firecrawl is designed to:
- Convert HTML into LLM-ready markdown
- Crawl links from web pages
- Extract text from rendered pages

**For KAP scraping, Firecrawl is not optimal because:**

1. **PDF Files, Not Web Pages:**
   - KAP serves actual PDF *files*, not web pages
   - Firecrawl is optimized for text extraction, not binary file downloading

2. **Efficiency:**
   - API approach: 500+ records in 1 second
   - HTML crawling: Would require rendering JavaScript, scrolling, clicking thousands of elements

3. **Reliability:**
   - API provides structured data directly
   - HTML parsing is fragile and breaks with UI changes

**However:** If you need to parse PDF *content* after downloading, you can:
1. Use API to get PDF URLs (current approach)
2. Download PDFs
3. Pass downloaded PDFs to PDF parser (like `pypdf`, `PyMuPDF`, or `LlamaParse`)
4. Then use Firecrawl/LLM for text analysis if needed

---

## Roadmap for Full Implementation

### âœ… Completed

- [x] API endpoint discovery
- [x] POST request implementation
- [x] JSON response parsing
- [x] Database storage of metadata
- [x] PDF URL construction

### ðŸ”„ In Progress / Optional

- [ ] PDF download automation (can use existing `PDFDownloader` utility)
- [ ] Batch processing for large date ranges
- [ ] Retry logic for failed requests
- [ ] Rate limiting to be polite to server
- [ ] PDF text extraction integration
- [ ] Sentiment analysis on extracted text

### ðŸ“‹ Future Enhancements

- [ ] Filter by specific disclosure classes (e.g., "FR" for Financial Reports)
- [ ] Filter by company symbols
- [ ] Handle attachments (ek files)
- [ ] Incremental updates (only fetch new reports)
- [ ] Webhook notifications for new reports
- [ ] Scheduled scraping (cron jobs)

---

## Usage Example

```python
from scrapers.kap_scraper import KAPScraper
from database.db_manager import DatabaseManager

# Initialize
db_manager = DatabaseManager()
scraper = KAPScraper(db_manager=db_manager)

# Scrape last 7 days
result = await scraper.scrape(days_back=7)

# Results contain:
# - Metadata in database
# - PDF URLs in data.url field
# - All API response data preserved
```

---

## Key Takeaways

1. **KAP is a SPA** - Use API, not HTML crawling
2. **API is efficient** - 500+ records in seconds
3. **disclosureIndex is key** - Use it to construct PDF URLs
4. **Date format matters** - Use `YYYY-MM-DD` (confirmed working)
5. **Firecrawl for PDFs?** - Use API to get URLs, then download/parse separately

---

## References

- Working implementation: `getData_ff/src/getKAPReports.py`
- Current implementation: `examples/turkish-financial-data-scraper/scrapers/kap_scraper.py`
- API endpoint: `https://www.kap.org.tr/tr/api/memberDisclosureQuery`
- PDF URL pattern: `https://www.kap.org.tr/tr/BildirimPdf/{disclosureIndex}`
